{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; \n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/lucascheng24/COMP4432ML-DataProduct-A_Million_News_Headlines/main/raw_data/abcnews-date-text.csv'\n",
    "\n",
    "\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "headlines = df['headline_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampleSize:  62209\n"
     ]
    }
   ],
   "source": [
    "# Sample size\n",
    "sampleSize = len(headlines) // 20   # 5%\n",
    "analyze_random_state = 4432\n",
    "\n",
    "print(\"sampleSize: \", sampleSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(n = sampleSize, random_state = analyze_random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publish_date</th>\n",
       "      <th>headline_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>157663</th>\n",
       "      <td>20050415</td>\n",
       "      <td>govt urged to release sustainability grants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53129</th>\n",
       "      <td>20031104</td>\n",
       "      <td>whatmore names side for one dayers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946324</th>\n",
       "      <td>20150422</td>\n",
       "      <td>driverless cars adelaide trials closer accordi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1062810</th>\n",
       "      <td>20161216</td>\n",
       "      <td>star wars quiz: test your knowledge of a galax...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210891</th>\n",
       "      <td>20060106</td>\n",
       "      <td>student success ascribed to support network</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         publish_date                                      headline_text\n",
       "157663       20050415        govt urged to release sustainability grants\n",
       "53129        20031104                 whatmore names side for one dayers\n",
       "946324       20150422  driverless cars adelaide trials closer accordi...\n",
       "1062810      20161216  star wars quiz: test your knowledge of a galax...\n",
       "210891       20060106        student success ascribed to support network"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates('headline_text')\n",
    "headlines = df['headline_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lucas\\AppData\\Local\\Temp\\ipykernel_17536\\1985888636.py:12: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  preprocessed_headlines_np = np.array(preprocessed_headlines)\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "punctuation = set(string.punctuation)\n",
    "\n",
    "def preprocess(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens = [token for token in tokens if token not in stop_words and token not in punctuation]\n",
    "    return tokens\n",
    "\n",
    "preprocessed_headlines = [preprocess(headline) for headline in headlines]\n",
    "\n",
    "# Convert preprocessed_headlines to a NumPy array\n",
    "preprocessed_headlines_np = np.array(preprocessed_headlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_df = df\n",
    "preprocessed_df['headline_text'] = preprocessed_headlines_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stem = PorterStemmer()\n",
    "def stemmer(txt_arr):\n",
    "    return [stem.stem(w) for w in txt_arr]\n",
    "\n",
    "lem = WordNetLemmatizer()\n",
    "def lemma(txt_arr):\n",
    "    return [lem.lemmatize(w) for w in txt_arr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publish_date</th>\n",
       "      <th>headline_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>157663</th>\n",
       "      <td>20050415</td>\n",
       "      <td>[govt, urged, release, sustainability, grant]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53129</th>\n",
       "      <td>20031104</td>\n",
       "      <td>[whatmore, name, side, one, dayers]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946324</th>\n",
       "      <td>20150422</td>\n",
       "      <td>[driverless, car, adelaide, trial, closer, acc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1062810</th>\n",
       "      <td>20161216</td>\n",
       "      <td>[star, war, quiz, test, knowledge, galaxy, far...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210891</th>\n",
       "      <td>20060106</td>\n",
       "      <td>[student, success, ascribed, support, network]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1082965</th>\n",
       "      <td>20170523</td>\n",
       "      <td>[former, world, champion, nicky, hayden, dy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465365</th>\n",
       "      <td>20090528</td>\n",
       "      <td>[swine, flu, ship, quarantined]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987189</th>\n",
       "      <td>20151021</td>\n",
       "      <td>[disgraced, former, png, police, chief, geoffr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871078</th>\n",
       "      <td>20140501</td>\n",
       "      <td>[diesel, rebate, cut, fear]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1135701</th>\n",
       "      <td>20180726</td>\n",
       "      <td>[afl, dream, turn, dust, bailey, banfield, fre...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61609 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         publish_date                                      headline_text\n",
       "157663       20050415      [govt, urged, release, sustainability, grant]\n",
       "53129        20031104                [whatmore, name, side, one, dayers]\n",
       "946324       20150422  [driverless, car, adelaide, trial, closer, acc...\n",
       "1062810      20161216  [star, war, quiz, test, knowledge, galaxy, far...\n",
       "210891       20060106     [student, success, ascribed, support, network]\n",
       "...               ...                                                ...\n",
       "1082965      20170523       [former, world, champion, nicky, hayden, dy]\n",
       "465365       20090528                    [swine, flu, ship, quarantined]\n",
       "987189       20151021  [disgraced, former, png, police, chief, geoffr...\n",
       "871078       20140501                        [diesel, rebate, cut, fear]\n",
       "1135701      20180726  [afl, dream, turn, dust, bailey, banfield, fre...\n",
       "\n",
       "[61609 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_df['headline_text'] = df['headline_text'].apply(lemma)\n",
    "preprocessed_df['pos_tags'] = preprocessed_df['headline_text'].apply(lambda x: nltk.pos_tag(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessed_df['headline_text'].apply(nltk.pos_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publish_date</th>\n",
       "      <th>headline_text</th>\n",
       "      <th>pos_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>157663</th>\n",
       "      <td>20050415</td>\n",
       "      <td>[govt, urged, release, sustainability, grant]</td>\n",
       "      <td>[(govt, NN), (urged, VBD), (release, NN), (sus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53129</th>\n",
       "      <td>20031104</td>\n",
       "      <td>[whatmore, name, side, one, dayers]</td>\n",
       "      <td>[(whatmore, NN), (name, NN), (side, NN), (one,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946324</th>\n",
       "      <td>20150422</td>\n",
       "      <td>[driverless, car, adelaide, trial, closer, acc...</td>\n",
       "      <td>[(driverless, NN), (car, NN), (adelaide, IN), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1062810</th>\n",
       "      <td>20161216</td>\n",
       "      <td>[star, war, quiz, test, knowledge, galaxy, far...</td>\n",
       "      <td>[(star, JJ), (war, NN), (quiz, JJ), (test, NN)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210891</th>\n",
       "      <td>20060106</td>\n",
       "      <td>[student, success, ascribed, support, network]</td>\n",
       "      <td>[(student, NN), (success, NN), (ascribed, VBD)...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         publish_date                                      headline_text  \\\n",
       "157663       20050415      [govt, urged, release, sustainability, grant]   \n",
       "53129        20031104                [whatmore, name, side, one, dayers]   \n",
       "946324       20150422  [driverless, car, adelaide, trial, closer, acc...   \n",
       "1062810      20161216  [star, war, quiz, test, knowledge, galaxy, far...   \n",
       "210891       20060106     [student, success, ascribed, support, network]   \n",
       "\n",
       "                                                  pos_tags  \n",
       "157663   [(govt, NN), (urged, VBD), (release, NN), (sus...  \n",
       "53129    [(whatmore, NN), (name, NN), (side, NN), (one,...  \n",
       "946324   [(driverless, NN), (car, NN), (adelaide, IN), ...  \n",
       "1062810  [(star, JJ), (war, NN), (quiz, JJ), (test, NN)...  \n",
       "210891   [(student, NN), (success, NN), (ascribed, VBD)...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Extraction/Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>01</th>\n",
       "      <th>02</th>\n",
       "      <th>03</th>\n",
       "      <th>06</th>\n",
       "      <th>07</th>\n",
       "      <th>0702</th>\n",
       "      <th>09</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>...</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoning</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zookeeper</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zuckerberg</th>\n",
       "      <th>zuma</th>\n",
       "      <th>zurich</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 14936 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   000   01   02   03   06   07  0702   09   10  100  ...  zoe  zombie  zone  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  ...  0.0     0.0   0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  ...  0.0     0.0   0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  ...  0.0     0.0   0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  ...  0.0     0.0   0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  ...  0.0     0.0   0.0   \n",
       "5  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  ...  0.0     0.0   0.0   \n",
       "6  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  ...  0.0     0.0   0.0   \n",
       "7  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  ...  0.0     0.0   0.0   \n",
       "8  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  ...  0.0     0.0   0.0   \n",
       "9  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  ...  0.0     0.0   0.0   \n",
       "\n",
       "   zoning  zoo  zookeeper  zoom  zuckerberg  zuma  zurich  \n",
       "0     0.0  0.0        0.0   0.0         0.0   0.0     0.0  \n",
       "1     0.0  0.0        0.0   0.0         0.0   0.0     0.0  \n",
       "2     0.0  0.0        0.0   0.0         0.0   0.0     0.0  \n",
       "3     0.0  0.0        0.0   0.0         0.0   0.0     0.0  \n",
       "4     0.0  0.0        0.0   0.0         0.0   0.0     0.0  \n",
       "5     0.0  0.0        0.0   0.0         0.0   0.0     0.0  \n",
       "6     0.0  0.0        0.0   0.0         0.0   0.0     0.0  \n",
       "7     0.0  0.0        0.0   0.0         0.0   0.0     0.0  \n",
       "8     0.0  0.0        0.0   0.0         0.0   0.0     0.0  \n",
       "9     0.0  0.0        0.0   0.0         0.0   0.0     0.0  \n",
       "\n",
       "[10 rows x 14936 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create an instance of TfidfVectorizer with tf-idf;\n",
    "tf = TfidfVectorizer(stop_words = 'english', use_idf = True, norm = 'l2', min_df=2, max_df=0.3)\n",
    "\n",
    "# convert text to features\n",
    "text_tokens_tfidf = tf.fit_transform([' '.join(x) for x in preprocessed_df['headline_text']])\n",
    "\n",
    "# get feature names\n",
    "feature_names = tf.get_feature_names_out()\n",
    "\n",
    "# print the first several examples and the features\n",
    "feature_matrix = pd.DataFrame(text_tokens_tfidf.toarray()[:10], columns = feature_names)\n",
    "\n",
    "feature_matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m<__array_function__ internals>:2\u001b[0m, in \u001b[0;36mwhere\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'sklearn.cluster._k_means_common._relocate_empty_clusters_sparse'\n",
      "Traceback (most recent call last):\n",
      "  File \"<__array_function__ internals>\", line 2, in where\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "wcss = []\n",
    "for i in range(1,21):\n",
    "    kmeans = KMeans(n_clusters=i,random_state=0)\n",
    "    kmeans.fit(text_tokens_tfidf)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "plt.plot(range(1,21),wcss)\n",
    "plt.title('The Elbow Method')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('WCSS')\n",
    "#plt.savefig('elbow.png')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering Hierarchical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kMean = KMeans(n_clusters=10,)\n",
    "kMean.fit(text_tokens_tfidf)\n",
    "\n",
    "print(\"Top terms per cluster:\")\n",
    "common = kMean.cluster_centers_.argsort()[:, ::-1]\n",
    "print(common)\n",
    "terms = tf.get_feature_names_out()\n",
    "for i in range(10):\n",
    "    print(\"Cluster:\",i),\n",
    "    for ind in common[i, :50]:\n",
    "        print(terms[ind])\n",
    "    print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

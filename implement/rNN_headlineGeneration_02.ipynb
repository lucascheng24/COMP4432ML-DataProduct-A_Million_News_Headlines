{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lucascheng24/COMP4432ML-DataProduct-A_Million_News_Headlines/blob/main/implement/rNN_headlineGeneration_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "F7sgr2HE32mC"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRLHaUrc31Pp",
        "outputId": "8cf7b6ce-d7a2-4109-827a-c30c7ffd6a39"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 2)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "url = 'https://raw.githubusercontent.com/lucascheng24/COMP4432ML-DataProduct-A_Million_News_Headlines/main/raw_data/abcnews-date-text.csv'\n",
        "\n",
        "# Load the headlines dataset\n",
        "df = pd.read_csv(url)\n",
        "df.head(10)\n",
        "\n",
        "# Sample size\n",
        "sampleSize = len(df) // 50   # 5%\n",
        "analyze_random_state = 4432\n",
        "sample_df = df.sample(n = 10000, random_state = analyze_random_state)\n",
        "sample_df.shape\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "fzRIz7Kk402Z"
      },
      "outputs": [],
      "source": [
        "# Preprocess the data\n",
        "max_words = 5000  # reduce the vocabulary size\n",
        "max_len = 10  # reduce the sequence length\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(sample_df['headline_text'])\n",
        "sequences = tokenizer.texts_to_sequences(sample_df['headline_text'])\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_len, padding='post')\n",
        "target = tf.keras.utils.to_categorical(padded_sequences, num_classes=max_words)\n",
        "\n",
        "# Define a generator function to yield batches of data\n",
        "def data_generator(data, target, max_len, batch_size):\n",
        "    while True:\n",
        "        indices = np.random.choice(len(data), batch_size)\n",
        "        batch = data[indices]\n",
        "        batch_target = target[indices]\n",
        "        yield batch, batch_target\n",
        "\n",
        "# Create tf.data dataset\n",
        "batch_size = 16\n",
        "dataset = tf.data.Dataset.from_generator(\n",
        "    data_generator,\n",
        "    args=[padded_sequences, target, max_len, batch_size],\n",
        "    output_types=(tf.int32, tf.int32),\n",
        "    output_shapes=([None, max_len], [None, max_words])\n",
        ")\n",
        "\n",
        "# Define the RNN model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=max_words, output_dim=32, input_length=max_len),\n",
        "    tf.keras.layers.LSTM(32),\n",
        "    tf.keras.layers.Dense(max_words, activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "T6gbPFsE3xoO"
      },
      "outputs": [],
      "source": [
        "# Generate new headlines based on input keywords\n",
        "def generate_headline(model, tokenizer, keywords, max_len, num_words=1):\n",
        "    # Convert the keywords to a sequence of integers\n",
        "    keyword_seq = tokenizer.texts_to_sequences([keywords])[0]\n",
        "    # Pad the sequence to match the maximum length of the training data\n",
        "    padded_seq = pad_sequences([keyword_seq], maxlen=max_len, padding='post')\n",
        "    # Generate the next words in the sequence using the model\n",
        "    for i in range(num_words):\n",
        "        next_word_index = np.argmax(model.predict(padded_seq)[0])\n",
        "        # Convert the integer back to a word using the tokenizer\n",
        "        next_word = tokenizer.index_word[next_word_index]\n",
        "        # Append the next word to the sequence\n",
        "        padded_seq = np.append(padded_seq[:, 1:], [[next_word_index]], axis=1)  # remove the first word from the sequence\n",
        "    # Convert the sequence of integers back to a sentence using the tokenizer\n",
        "    generated_headline = tokenizer.sequences_to_texts(padded_seq)[0]\n",
        "    # Return the generated headline\n",
        "    return generated_headline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkyjYvkR3yYF",
        "outputId": "22da1e1f-f19e-4a11-c161-9b65cf8ada66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "super herald aust aust motorbike\n"
          ]
        }
      ],
      "source": [
        "# Generate a new headline based on list of input keywords\n",
        "generated_headline = generate_headline(model, tokenizer, ['man', 'car'], max_len, num_words=5)\n",
        "print(generated_headline)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNai4NPeliq1nFGBy7TG01o",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
